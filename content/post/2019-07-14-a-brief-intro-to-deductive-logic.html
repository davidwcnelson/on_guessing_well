---
title: An Introduction to Deductive Reasoning
author: David W.C. Telson
date: '2019-07-14'
slug: an-introduction-to-deductive-reasoning
categories: []
tags: []
draft: TRUE
---



<p>One of my absolute favorites books is <a href="http://www.med.mcgill.ca/epidemiology/hanley/bios601/GaussianModel/JaynesProbabilityTheory.pdf"><em>Probability: the Logic of Science</em> by E.T. Jaynes</a>. The book was published posthumously in 2003, after Jayne’s death in 1998. While the book presents a compelling philosophical argument for probability theory, <a href="http://ksvanhorn.com/bayes/jaynes/">it is known to be incomplete and to contain errors</a>. Despite this, I think it is a very important work in the history of probability theory, and a great foundation for how one can reason with incomplete information.</p>
<p>In the initial chapters of the book, Jaynes begins with an introduction to <a href="https://en.wikipedia.org/wiki/Deductive_reasoning">deductive logic</a>, which is considered by many to be the “gold standard” of reasoning. After Jaynes explicates the general concept of deductive logic, he goes on to expand it to cases where there is insufficient information to perform deduction via reference to <a href="https://en.wikipedia.org/wiki/George_P%C3%B3lya">George Polya</a>’s <a href="https://en.wikipedia.org/wiki/Mathematics_and_Plausible_Reasoning">plausible reasoning</a>. It is only after this point that he invokes <a href="https://en.wikipedia.org/wiki/Cox%27s_theorem">Cox’s theorem</a> to quantify plausible reasoning into the familiar form of probability theory.</p>
<p>With all that said, I thought it would be useful to explore deductive reasoning on our own, to serve as a foundation for plausible, and then probabilistic reasoning in the same vein as Jaynes. I will admit that this is pedagogical for my own understanding as well. Aside from using Jayne’s book, I also will reference ideas from the book <a href="https://www.amazon.com/How-Prove-Structured-Approach-2nd/dp/0521675995"><em>How to Prove It</em> by Daniel Velleman</a>.</p>
<p>We begin with the notion of a proposition. We define a proposition as a statement about the universe that is either true or false. There is a lot more to the nature of propositions e.g. the implications of <a href="https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems">Gödel’s famous incompleteness theorems</a>; but we will hold these ideas back for now. Here are some propositions we could consider:</p>
<ul>
<li><p><span class="math inline">\(P_1 \equiv ``\text{My favorite color is purple.&#39;&#39;}\)</span></p></li>
<li><p><span class="math inline">\(P_2 \equiv ``\text{It will rain today.&#39;&#39;}\)</span></p></li>
</ul>
<p><em>Author’s note: I apologize for the use of in-quote and out-quote punctuation. I am hoping to make it clear that a proposition is a complete statement, while also closing out my sentences with appropriate punctuation. I recognize there might be a better way to do so.</em></p>
<p>Notice that we use the <span class="math inline">\(\equiv\)</span> sign rather than <span class="math inline">\(=\)</span>, as we mean “equivalent by definition”, that is <span class="math inline">\(P_1\)</span> actually stands for <span class="math inline">\(``\text{My favorite color is purple.&#39;&#39;}\)</span>, or more precisely <span class="math inline">\(P_1\)</span> and <span class="math inline">\(``\text{My favorite color is purple.&#39;&#39;}\)</span> have the same “truth value”. Also note that <span class="math inline">\(P_1\)</span> is an opinion (held by me), rather than some universal truth.
Both propositions are both vague in some sense, e.g. when is “today?” and what geography is this limited to, as surely it is bound to rain some amount somewhere on the planet we call “Earth” today. We do not let this vagueness bother us for now.</p>
<p>Both of these propositions have a “truth” value, that is they are necessarily either true or false (<a href="https://plato.stanford.edu/entries/logic-many%20valued/">at least in the form of logic we are using</a>). We sometimes write something that is always true (also called a <a href="https://en.wikipedia.org/wiki/Tautology_(logic)">tautology</a>) as <span class="math inline">\(\top\)</span>, and something that is always false (also called a <a href="https://en.wikipedia.org/wiki/Contradiction">contradiction</a>) as <span class="math inline">\(\bot\)</span>. We use deductive logic to reason about the truth or falsity about a proposition, given other propositions and logical connectives (also called logical operators) between them.</p>
<p>The first logical operator we will discuss is called negation, written as <span class="math inline">\(\neg\)</span>. We use negation in tandem with a proposition, e.g. <span class="math inline">\(\neg P\)</span>. What does negation do? Intuitively it gives us the opposite (or negative) of the proposition e.g., if <span class="math inline">\(P_2 \equiv ``\text{It will rain today.&#39;&#39;}\)</span>, then <span class="math inline">\(\neg P_2 \equiv ``\text{It will not rain today.&#39;&#39;}\)</span>. If we say that <span class="math inline">\(P_3 \equiv \neg P_2\)</span>, then <span class="math inline">\(\neg P_3 \equiv \neg\neg P_2 \equiv P_2\)</span>. This operator will be very useful in practice.</p>
<p>The next operator we wish to introduce is “disjunction”, or more intuitively, the “or” operator, symbolized with <span class="math inline">\(\vee\)</span>. Whereas <span class="math inline">\(\neg\)</span> was a “unary” (with the prefix “un” as in one e.g., unity) operator, <span class="math inline">\(\vee\)</span> is a “binary” operator i.e. an operator that works on two propositions. For instance, we could say <span class="math inline">\(P_2 \vee P_3\)</span>, that is <span class="math inline">\(``\text{Either it will or will not rain today.&#39;&#39;}\)</span>. We could assign this disjunction to a proposition <span class="math inline">\(P_4 \equiv P_2 \vee P_3\)</span>. Disjunction is not exclusive: one or both of the propositions can be true for the disjunction to return true. An “exclusive disjunction” or “XOR” operator does exist, and is often symbolizes with <span class="math inline">\(\oplus\)</span>.</p>
<p>Notice that since <span class="math inline">\(P_3 \equiv \neg P_2\)</span>, we have <span class="math inline">\(P_4 \equiv P_2 \vee \neg P_2\)</span>. Since <span class="math inline">\(P_2\)</span> is either true or false, and its negation has the opposite truth value, we must have <span class="math inline">\(P_4 \equiv P_2 \vee \neg P_2 \equiv \top\)</span>, that is <span class="math inline">\(P_4\)</span> must always be true i.e. <span class="math inline">\(P_4\)</span> is a tautology. This is not necessarily true of all disjunctions, just in the case where we have a disjunction of a proposition and its negation.</p>
<p>The opposite of “disjunction” could be considered to be “conjunction”, that is the “and” operator, symbolized with <span class="math inline">\(\wedge\)</span>. Like <span class="math inline">\(\vee\)</span>, <span class="math inline">\(\wedge\)</span> works on two propositions, e.g. <span class="math inline">\(P_6 \equiv P_5 \wedge P_2 \equiv``\text{It will be cloudy today and it will rain today.&#39;&#39;}\)</span>, where <span class="math inline">\(P_5 \equiv `\text{It will be cloudy today.&#39;&#39;}\)</span>. Notice the effect when we use conjunction on a proposition and its negation: <span class="math inline">\(P_7 \equiv P_2 \wedge \neg P_2 \equiv \bot\)</span>, i.e. the conjunction of a proposition and its negation is necessarily false i.e. it is a contradiction.</p>
<p>Interestingly, we don’t actually need to define conjunction to use it: it can be derived from disjunction and negation. Even more interesting is that all three logical operators can be derived from one of two single operators, referred to as <a href="https://en.wikipedia.org/wiki/Sheffer_stroke">NAND</a> (not both) with the symbol <span class="math inline">\(\uparrow\)</span>, and <a href="https://en.wikipedia.org/wiki/Logical_NOR">NOR</a> (not either) with the symbol <span class="math inline">\(\downarrow\)</span>. We’re not going to get into concept of “<a href="https://en.wikipedia.org/wiki/Functional_completeness">functional completeness</a>”, but it is really cool and I highly suggest you check it out.</p>
<p>Before we go any further, we should really talk about “<a href="https://en.wikipedia.org/wiki/Truth_table">Truth Tables</a>”. A truth table is an incredibly useful tool in deductive logic that lets us understand the relationships between propositions given all possible truth values the propositions could assume. What follows is a truth table for two arbitrary propositions <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> and their conjunction <span class="math inline">\(P \wedge Q\)</span>. Here <span class="math inline">\(T\)</span> represents a truth value of “True” and <span class="math inline">\(F\)</span> stands for a truth value of “False”:</p>
<p><span class="math display">\[
\begin{array}{|c|c|c|}
P &amp; Q &amp; P \wedge Q\\ 
\hline 
T &amp; T &amp; T\\
T &amp; F &amp; F\\
F &amp; T &amp; F\\
F &amp; F &amp; F\\
\end{array}
\]</span></p>
<p>We can extend this table to show all of our elementary logical operators:</p>
<p><span class="math display">\[
\begin{array}{|c|c|c|c|c|}
P &amp; Q &amp; \neg P &amp; P \wedge Q &amp; P \vee Q\\ 
\hline 
T &amp; T &amp; F &amp; T &amp; T\\
T &amp; F &amp; F &amp; F &amp; T\\
F &amp; T &amp; T &amp; F &amp; T\\
F &amp; F &amp; T &amp; F &amp; F\\
\end{array}
\]</span></p>
<p>We can even include a third proposition, and look at the relationships implied, for instance:</p>
<p><span class="math display">\[
\begin{array}{|c|c|c|c|}
P &amp; Q &amp; R &amp; P \vee Q \vee R\\ 
\hline 
T &amp; T &amp; T &amp; T \\
T &amp; T &amp; F &amp; T \\
T &amp; F &amp; T &amp; T \\
F &amp; T &amp; T &amp; T \\
F &amp; F &amp; T &amp; T \\
F &amp; T &amp; F &amp; T \\
T &amp; F &amp; F &amp; T \\
F &amp; F &amp; F &amp; F \\
\end{array}
\]</span></p>
<p>As we add propositions that are independent (where its truth value is not determined by the truth values of the other propositions) with non trivial truth values (i.e. not contradictions or tautologies), we have to add additional rows to our truth table. Can we determine how many rows will be required given a number of independent propositions with non-trivial truth values? Yes we can! Let’s examine how:</p>
<ul>
<li><p>A single independent non-trivial proposition can take on one of two truth values, either <span class="math inline">\(T\)</span> or <span class="math inline">\(F\)</span>.</p></li>
<li><p>Two independent non-trivial propositions can collectively take on one of four possibilities, either <span class="math inline">\(\{T,T\}\)</span>, <span class="math inline">\(\{T,F\}\)</span>, <span class="math inline">\(\{F,T\}\)</span>, or <span class="math inline">\(\{F,F\}\)</span>.</p></li>
<li><p>Using the same reasoning, we can see that <span class="math inline">\(n\)</span> independent and non-trivial propositions can take on one of <span class="math inline">\(2^n\)</span> possible values.</p></li>
</ul>
<p>So we need a truth table with <span class="math inline">\(2^n\)</span> rows to represent <span class="math inline">\(n\)</span> independent and non-trivial propositions. The number of columns depends on what relations among the propositions we care to examine.</p>
<p>We should note that the logical operators discussed thus far have an order of operations just like in arithmetic or algebra. Technically this order is arbitrary, but in this article we adopt the <a href="https://en.wikipedia.org/wiki/Logical_connective#Order_of_precedence">order of precedence featured in this article</a>. Additionally, logical relations among propositions have a number of equivalencies that help to simplify the analysis of their truth values. We don’t dive into these equivalencies in this post, but <a href="https://en.wikipedia.org/wiki/Logical_equivalence">some useful ones are listed here</a>.</p>
<p>With the concept of propositions, logical connectives, and truth tables under our belt, we can now speak to the crown jewel of deductive reasoning: the deductive argument. First we wish to define another logical operator, known as “implication”, which is symbolizes as <span class="math inline">\(\implies\)</span>. We say that <span class="math inline">\(P \implies Q\)</span> if whenever <span class="math inline">\(P\)</span> is true, <span class="math inline">\(Q\)</span> is also true. Note that “implies” doesn’t have the same meaning it does in common speech: implication indicates no causal relationship between <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span>. It doesn’t even mean that if <span class="math inline">\(P\)</span> is false, then <span class="math inline">\(Q\)</span> is necessarily false, only that when <span class="math inline">\(P\)</span> is true, <span class="math inline">\(Q\)</span> is also true. Let’s examine the truth table of implication.</p>
<p><span class="math display">\[
\begin{array}{|c|c|c|}
P &amp; Q &amp; P \implies Q\\ 
\hline 
T &amp; T &amp; T\\
T &amp; F &amp; F\\
F &amp; T &amp; T\\
F &amp; F &amp; T\\
\end{array}
\]</span></p>
<p>A keen observer might note that implication is identical to <span class="math inline">\(\neg P \vee Q\)</span>:</p>
<p><span class="math display">\[
\begin{array}{|c|c|c|c|c|}
P &amp; Q &amp; \neg P &amp; \neg P \vee Q &amp; P \implies Q\\ 
\hline 
T &amp; T &amp; F &amp; T &amp; T\\
T &amp; F &amp; F &amp; F &amp; F\\
F &amp; T &amp; T &amp; T &amp; T\\
F &amp; F &amp; T &amp; T &amp; T\\
\end{array}
\]</span></p>
<p>An extension of implication that we note here, but will not dive any further into is the “bi-conditional”, or “if and only if”, symbolized <span class="math inline">\(\iff\)</span>. It is an implication that goes both ways, e.g., <span class="math inline">\(P \iff Q \equiv (P\implies Q)\wedge(Q\implies P)\)</span>.</p>
<p>Using <span class="math inline">\(\implies\)</span>, we can make deductive arguments, that is we can reason deductively. The form of a deductive argument is simple: we begin with some premises and we determine the truth of a conclusion.</p>
<p>Suppose we are given that the propositions <span class="math inline">\(``\text{If it is rainy today, it is cloudy today.&#39;&#39;}\)</span> and <span class="math inline">\(``\text{It is rainy today.&#39;&#39;}\)</span> are both true. We can therefore conclude the proposition <span class="math inline">\(``\text{It is cloudy today.&#39;&#39;}\)</span> is true. This conclusion is necessarily true i.e. it is required by the premises. Don’t let the content of the statements get in the way of your thinking: its the form that matters, not the content.</p>
<p>We can restate our deductive argument symbolically, with <span class="math inline">\(P \equiv ``\text{It is rainy today.&#39;&#39;}\)</span>, <span class="math inline">\(Q \equiv ``\text{It is cloudy today.&#39;&#39;}\)</span>, and <span class="math inline">\(\therefore\)</span> means “therefore”:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \ P \implies Q\\
&amp; \ P \\
\hline
&amp; \therefore \ Q
\end{aligned}
\]</span></p>
<p>If we examine the truth table for implication, we see that in the row where <span class="math inline">\(P \implies Q\)</span> and <span class="math inline">\(P\)</span> are both true, <span class="math inline">\(Q\)</span> is also true. There are no other cases where both premises are true, so the truth value of <span class="math inline">\(Q\)</span> is forced upon us! This is the power of deductive logic: the premises guarantee the truth value of the conclusion. This specific form of reasoning is referred to as “<a href="https://en.wikipedia.org/wiki/Modus_ponens">Modus Ponens</a>”, which is Latin for “affirming by affirming”.</p>
<p>Note that the converse is not true i.e. that is if we know <span class="math inline">\(Q\)</span>, we cannot guarantee that <span class="math inline">\(P\)</span> is also true. This is because <span class="math inline">\(P\)</span> can be true or false given that <span class="math inline">\(Q\)</span> is true. This can be seen via the truth table for implication. This is a <a href="https://en.wikipedia.org/wiki/Formal_fallacy">formal fallacy</a> (i.e. error of form) referred to as “<a href="https://en.wikipedia.org/wiki/Affirming_the_consequent">Affirming the Consequent</a>”. This fallacy is equivalent to the form of “<a href="https://en.wikipedia.org/wiki/Abductive_reasoning#Deduction,_induction,_and_abduction">abductive reasoning</a>” i.e. reasoning to the best explanation. We will have a lot more to say of this in the future.</p>
<p>A deductive argument that suffers from an error of form is said to be “invalid”. An argument whose conclusions are guaranteed by its premises is said to be valid. A deductive argument whose premises are false is referred to as “unsound”, whereas an argument whose premises are true is referred to as “sound.” The soundness of an argument cannot necessarily be guaranteed by form of the argument! This is an important issue that has major implications for how we reason in the real world.</p>
<p>Implication also gives us another form of deductive argument through “Modus Tollens”, which is Latin for “denying by denying”. It takes the following symbolic form:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \ P \implies Q\\
&amp; \ \neg Q \\
\hline
&amp; \therefore \ \neg P
\end{aligned}
\]</span></p>
<p>This line of reasoning is guaranteed as demonstrated via the truth table for implication. Further, it is the mode of reasoning advocated by the <a href="https://en.wikipedia.org/wiki/Philosophy_of_science">philosopher of science</a> <a href="https://en.wikipedia.org/wiki/Karl_Popper">Karl Popper</a> to resolve <a href="https://en.wikipedia.org/wiki/David_Hume">David Hume</a>’s “<a href="https://stanford.library.sydney.edu.au/archives/sum2016/entries/induction-problem/">Problem of Induction</a>”. Popper’s program is referred to as <a href="https://en.wikipedia.org/wiki/Falsifiability">Falsificationism</a>, and will be of interest to us later, as will “the Problem of Induction.”</p>
<p>Deductive reasoning is the workhorse of logic and <a href="https://en.wikipedia.org/wiki/Mathematical_proof">mathemtical proof</a>. In principle we would like to apply deductive reasoning to all of our problems to ensure that our conclusions are guaranteed to be true; however in order to perform deductive logic we must adopt premises, and for our argument to be sound we must know that our premises are true. This is often a luxury that we do not have in addressing the problems that we wish to solve.</p>
<p>How then do we reason with insufficient information to perform deduction? Humans (and arguably other forms of life) reason with incomplete and uncertain information all of the time. How is it that we are successful in our endeavors? This is one of the great questions of <a href="https://plato.stanford.edu/entries/epistemology/">epistemology</a> (the philosophy of knowledge) and the <a href="https://en.wikipedia.org/wiki/Philosophy_of_science">philsophy of science</a> (arguably a sub-disciple of epistemology focusing on how we conduct science). The answer to which would have major implications for design and application of statistics and machine learning.</p>
<p>I look forward to exploring this question more over the course of this blog!</p>
