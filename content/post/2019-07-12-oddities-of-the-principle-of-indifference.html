---
title: "Some Oddities of the Principle of Insufficient Reason"
author: "David W.C. Telson"
date: '2019-07-12'
draft: TRUE
slug: some_oddities_of_the-principle-of-insufficient-reason
tags: null
categories: null
---



<p>We are keenly interested in reasoning with incomplete or uncertain information i.e. how we should make a “best guess” given that we have imperfect knowledge. One of the classical tools in our tool belt is the so called “principle of insufficient reason” also known as the “principle of indifference”. More on the history and extensions of the principle, but for now I want to focus on some oddities that occur by trying to reason with the principle.</p>
<p>The principle of insufficient reason essentially states that if we have <span class="math inline">\(n &gt; 1\)</span> mutually exclusive and collectively exhaustive propositions, and we have no reason to suspect any subset of them being more probable than another, then we should assign a probability of <span class="math inline">\(\frac{1}{n}\)</span> to each proposition.</p>
<p>In symbols we could rephrase this as follows: suppose <span class="math inline">\(a = \{a_1,a_2,...,a_n\}\)</span> is a collection of propositions such that <span class="math inline">\(\bigoplus_{i=1}^{n}a_i\)</span>. Here <span class="math inline">\(\oplus\)</span> is the “exclusive disjunction” i.e. “exclusive or” i.e. “XOR” operator, meaning that one and only one of the propositions is true. If we are unable to distinguish between the propositions except for their label <span class="math inline">\(i\)</span>, then the principle tells us to assign a probability of <span class="math inline">\(\frac{1}{n}\)</span> to each i.e. <span class="math inline">\(\forall a_i \in a\)</span>, <span class="math inline">\(p_i = P(a_i) = \frac{1}{n}\)</span>.</p>
<p>Even more abstractly, we could say that the principle of indifference is a function <span class="math inline">\(P\)</span>, defined as:
<span class="math display">\[
P: a \rightarrow \mathbb{R^+} \\
a_i \mapsto \frac{1}{|a|} = \frac{1}{n}  
\]</span></p>
<p>With finite sets of propositions, the principle satisfies the Kolmogorov’s axioms of probability. For a refresher, they are:</p>
<ol style="list-style-type: decimal">
<li>The probability of an event <span class="math inline">\(\omega\)</span> is a non-negative real number, i.e. <span class="math inline">\(P(\omega) \ge 0\)</span>.</li>
<li>The probability of any event occurring in the set of all possible events is 1, i.e. <span class="math inline">\(P(\Omega) = 1\)</span>.</li>
<li>The probability of a countable set of mutually exclusive events is equal to the sum of the probability of each of those events i.e. <span class="math inline">\(P(\bigcup_{i=1}^{\infty}\omega_i) = \sum_{i=1}^{\infty}P(\omega_i)\)</span>.</li>
</ol>
<p>The first two axioms are easily understood, but the last takes some thought. On finite sets, it is a triviality, but its utility is in finding meaningful probability statements within infinite sets, as we shall soon see.</p>
<p>The principle of indifference on a non-empty finite set of propositions meets the requirement of the first axiom easily, as any such set will have a cardinality <span class="math inline">\(0 &lt; |a| = n &lt; \infty\)</span> with <span class="math inline">\(n \in N\)</span> so that <span class="math inline">\(\frac{1}{n}\)</span> is always a positive real number.</p>
<p>The principle of indifference on a non-empty finite set of propositions also meets the requirement of the second axiom. Specifically, if we assume <span class="math inline">\(\bigoplus_{i=1}^{n}a_i\)</span>, then we have:</p>
<p><span class="math display">\[P(a) = P(\bigcup_{i=1}^{n}a_i) = \sum_{i=1}^{n}P(a_i)=\sum_{i=1}^n\frac{1}{n} = \frac{n}{n}=1\]</span>
<em>Note: technically this is a case of “abuse of notation” as we stated <span class="math inline">\(a_i\)</span> were propositions, rather than sets, but we will let this go for now.</em></p>
<p>Finally let’s choose to partition our set of propositions into two mutually exclusive subsets <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span> where <span class="math inline">\(|b| = m &lt; n\)</span> and <span class="math inline">\(|c| = n - m\)</span>. For the first subset we have:</p>
<p><span class="math display">\[P(b) = P(\bigcup_{a_i\in b}a_i) = \sum_{a_i\in b}P(a_i)=\sum_{i=1}^m\frac{1}{n} = \frac{m}{n}\lt1\]</span>
The second subset will have a probability equal to <span class="math inline">\(\frac{n-m}{n} = 1 - \frac{m}{n}\)</span>. These statements of the qualities of our principle of indifference are not so much proofs that our principle of indifference meets the axioms of probabilities as they are examples to build an intuition of how the two relate.</p>
<p>Now all of this is perfectly fine w.r.t. non-empty finite sets of mutually exclusive propositions, but what happens when we start to increase the number of propositions towards infinity? In other words, can our principle of indifference be applied to countably infinite sets? Let’s approach this from a different angle, and lets proceed cautiously by defining the limit of a sequence.</p>
<p><strong>Definition 1</strong> <em>The limit <span class="math inline">\(r\)</span> of a sequence <span class="math inline">\(f(n) = r_n\)</span> exists if for any <span class="math inline">\(\epsilon\)</span> &gt; 0, there exists an <span class="math inline">\(m \in \mathbb{N}\)</span> such that if <span class="math inline">\(n \ge m\)</span> then <span class="math inline">\(|r_n - r|&lt;\epsilon\)</span>. We write the limit <span class="math inline">\(r\)</span> of <span class="math inline">\(f(n)\)</span> as <span class="math inline">\(\lim_{n \to \infty} f(n) = r\)</span>.</em></p>
<p>So given a sequence (simply a function <span class="math inline">\(f: \mathbb{N} \to \mathbb{R}\)</span>), we can determine its limit given the definition. Let’s create a second definition for our purposes:</p>
<p><strong>Definition 2</strong> <em>A constant function is a function <span class="math inline">\(f\)</span> which maps any element <span class="math inline">\(x\)</span> in its domain <span class="math inline">\(X\)</span> to the only element <span class="math inline">\(c\)</span> of singleton set <span class="math inline">\(C\)</span> i.e. <span class="math inline">\(f\)</span> is a constant function if for all <span class="math inline">\(x \in X\)</span>, <span class="math inline">\(f(x) = c\)</span>.</em></p>
<p>When looking at the principle of indifference, we see that if <span class="math inline">\(a\)</span> is finite with cardinality <span class="math inline">\(|a| = n\)</span>, then <span class="math inline">\(\sum_{i=1}^{n}P(a_i) = \sum_{i=1}^{n}\frac{1}{n} = \frac{n}{n} = 1\)</span>. We can interpret this as a sequence taking a number of propositions and returning the sum of probabilities having invoked the principle of indifference i.e. <span class="math inline">\(f(n) = 1\)</span>. We can easily see that this is a constant function, and that for any <span class="math inline">\(n \in \mathbb{N}\)</span>, the principle of indifference yields probability assignments over all of the propositions that sum to 1, satisfying the first axiom of probability. What happens as <span class="math inline">\(n \to \infty\)</span>?</p>
<p><strong>Theorem 1</strong> <em>If <span class="math inline">\(f(n) = c\)</span> is a constant sequence, then its limit is <span class="math inline">\(c\)</span>.</em></p>
<p>To prove this theorem, we must show that <span class="math inline">\(\lim_{n \to \infty} f(n) = c\)</span> meets the criteria of <strong>Definition 1</strong>. We choose <span class="math inline">\(\epsilon &gt; 0\)</span> and any pair <span class="math inline">\(n, m\)</span> such that <span class="math inline">\(n \ge m\)</span> and <span class="math inline">\(n,m \in \mathbb{N}\)</span>. By <strong>Definition 2</strong> we have <span class="math inline">\(f(n) = f(m) = c\)</span>, so <span class="math inline">\(|c_n - c| = |c-c| = 0 &lt; \epsilon\)</span> as required. Thus <span class="math inline">\(\lim_{n \to \infty} f(n) = c\)</span>.</p>
<p>So the sum of the probabilities assigned via the principle of indifference converges to 1 as <span class="math inline">\(n\)</span> approaches <span class="math inline">\(\infty\)</span>. This is good news, as it tells us that the second axiom is satisfied by the probability assignments in the limit. Does the principle of indifference satisfy the remaining axioms as the number of propositions approaches infinity?</p>
<p><strong>Theorem 2</strong> <em><span class="math inline">\(\lim_{n \to \infty} \frac{1}{n} = 0\)</span>.</em></p>
<p>The proof is rather simple. Choose <span class="math inline">\(m &gt; \frac{1}{\epsilon}\)</span>, then for any <span class="math inline">\(n \ge m\)</span>, <span class="math inline">\(n &gt; \frac{1}{\epsilon}\)</span> which implies <span class="math inline">\(\frac{1}{n} &lt; \epsilon\)</span> which satisfies <span class="math inline">\(|\frac{1}{n}-0|&lt; \epsilon\)</span> as required. Thus <span class="math inline">\(\lim_{n \to \infty} \frac{1}{n} = 0\)</span>. This is a legitimate probability assignment to one proposition (because we must have <span class="math inline">\(P(a_i) \ge 0\)</span>), however it yields a problem in our prior reasoning, as if every proposition is assigned a uniform probability, then <span class="math inline">\(P(a_i) \ge 0\)</span> for all <span class="math inline">\(a_i \in a\)</span> i.e. <span class="math inline">\(\sum_{i=1}^{\infty}P(a_i)=0\)</span> which A) violates the second axiom, and B) contradicts our previous result! How could this have happened?</p>
<p>We are tackling this problem with two different limiting processes, that is:</p>
<p><span class="math display">\[\lim_{n \to \infty}\sum_{i=1}^{n}\frac{1}{n} = 1 \not= \lim_{n \to \infty}\sum_{i=1}^{n}\lim_{n \to \infty}\frac{1}{n} = \sum_{i=1}^{\infty}0=0\]</span></p>
<p>We are resigned to the fact that we cannot simultaneously take both limits (the limit of the sums and the sums of the limit). We could have encounter a similar result from a different perspective: assuming that <span class="math inline">\(u\)</span> is a probability assignment applied uniformly on a set of propositions, then <span class="math inline">\(\sum_{i=1}^{\infty}u\)</span> is either infinite or zero, neither of which satisfies the second axiom. These results are directly related to the fact that a computer cannot sample from a countably infinite set, but can easily sample from an arbitrarily large finite one.</p>
<p>One interesting question to ponder: if we cannot sample uniformly from a countably infinite set like the one described using a computer, how come we can sample from an uncountably infinite one such as a continuous uniform distribution defined on <span class="math inline">\([0,1]\)</span>? If we can sample from a continuous uniform on <span class="math inline">\([0,1]\)</span>, can we sample just the rational rational numbers in this range? I have two conjectures that I want to explore in the future:</p>
<ol style="list-style-type: decimal">
<li><p>If a set of numbers is bounded, then we can sample from a uniformly distribution defined on it.</p></li>
<li><p>If a set is a bounded interval (e.g., <span class="math inline">\([a,b]\)</span> with <span class="math inline">\(a, b \in \mathbb{R}\)</span>), then we can sample from a uniform distribution defined on it.</p></li>
</ol>
<p>The reason I think 1. and 2. are plausible is that I believe having a cumulative distribution function (CDF) makes it possible to sample using a computer. Since I can sample a number uniformly between <span class="math inline">\([0,1]\)</span> on a machine, if I have a CDF, I can feed the uniform sample into the inverse CDF to sample from the CDF.</p>
<p>The reason I doubt 1., but think 2. is more plausible is that the set <span class="math inline">\(\{1, \frac{1}{2}, \frac{1}{3}, \frac{1}{4},...\}\)</span> is bounded below by <span class="math inline">\(0\)</span> and above by <span class="math inline">\(1\)</span>, but is countably infinite and in fact is just the reciprocal of the natural numbers. Perhaps its the space between rational numbers that make it impossible to sample i.e. finitivity or bounded continuity is a requisite for sampling.</p>
<p>A quick visual of <span class="math inline">\(\{1, \frac{1}{2}, \frac{1}{3}, \frac{1}{4},...\}\)</span>:</p>
<pre class="r"><code>require(tidyverse)
require(scales)

qplot(x = 1/(1:100), y = &#39;&#39;) + 
  theme_minimal() + 
  labs(x = &#39;1/n&#39;) +
  scale_y_discrete(name = NULL, labels = NULL, breaks = NULL)</code></pre>
<p><img src="/post/2019-07-12-oddities-of-the-principle-of-indifference_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>The reason I think 2. might be too restrictive is the following set construction:</p>
<ul>
<li>Start with the numbers <span class="math inline">\(\frac{0}{1}\)</span> and <span class="math inline">\(\frac{1}{1}\)</span>.</li>
<li>Add the numerators and denominators <span class="math inline">\(\frac{0+1}{1+1} = \frac{1}{2}\)</span>.</li>
<li>Put the new element between the previous two elements.</li>
<li>Repeat for each new pair, but don’t insert the new numbers until all pairs are computed.</li>
</ul>
<p>The first few iterations look like this:</p>
<ol start="0" style="list-style-type: decimal">
<li><p><span class="math inline">\(\{\frac{0}{1},\frac{1}{1}\}\)</span></p></li>
<li><p><span class="math inline">\(\{\frac{0}{1},\frac{1}{2},\frac{1}{1}\}\)</span></p></li>
<li><p><span class="math inline">\(\{\frac{0}{1},\frac{1}{3},\frac{1}{2},\frac{2}{3},\frac{1}{1}\}\)</span></p></li>
<li><p><span class="math inline">\(\{\frac{0}{1},\frac{1}{4},\frac{1}{3},\frac{2}{5},\frac{1}{2},\frac{3}{5},\frac{2}{3},\frac{3}{4},\frac{1}{1}\}\)</span></p></li>
</ol>
<p>Let’s write a quick function to illustrate this set.</p>
<pre class="r"><code>f &lt;- function(n){
  
  numerators &lt;- c(0,1)
  
  denominators &lt;- c(1,1)
  
   new_numerators &lt;- numeric(0)
   
   new_denominators &lt;- numeric(0)
  
  for(i in 1:n){
    
    for(j in 1:(length(numerators)-1)){
      
      new_numerators &lt;- c(new_numerators, numerators[j] + numerators[j+1])
      
      new_denominators &lt;- c(new_denominators, denominators[j] + denominators[j+1])
      
    }
    
   new_order &lt;- order(c(numerators, new_numerators)/c(denominators, new_denominators))
    
   numerators &lt;- c(numerators, new_numerators)[new_order]  
    
   denominators &lt;- c(denominators, new_denominators)[new_order] 
    
   new_numerators &lt;- numeric(0)
   
   new_denominators &lt;- numeric(0)
    
  }
   
  return(numerators/denominators)
  
}

qplot(x = f(10), y = &#39;&#39;) + 
  theme_minimal() + 
  labs(x = &#39;x&#39;) +
  scale_y_discrete(name = NULL, labels = NULL, breaks = NULL)</code></pre>
<p><img src="/post/2019-07-12-oddities-of-the-principle-of-indifference_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>We can see the CDF of this function if we run it iteratively 10 times:</p>
<pre class="r"><code>tibble(x = f(10), y = cumsum(1:length(x))/sum(1:length(x))) %&gt;%
  ggplot() +
  geom_line(aes(x = x, y = y)) +
  theme_minimal() +
  scale_y_continuous(labels = percent)</code></pre>
<p><img src="/post/2019-07-12-oddities-of-the-principle-of-indifference_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>We could also see how the function changes for each iteration:</p>
<pre class="r"><code>map_df(1:12, function(n){
  
  f(n) %&gt;%
    tibble(n = n, x = .)
  
}) %&gt;%
  group_by(n) %&gt;%
  mutate(y = cumsum(1:length(x))/sum(1:length(x))) %&gt;%
  ggplot() +
  geom_line(aes(x = x, y = y)) +
  facet_wrap(~n) +
  theme_minimal() +
  scale_y_continuous(labels = percent)</code></pre>
<p><img src="/post/2019-07-12-oddities-of-the-principle-of-indifference_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Here we can see that a CDF, or at least an approximate CDF, exists. Again, if we assume that we need a CDF to sample from, then this looks like a candidate we can sample from that is not finite nor both bounded and continuous.</p>
<p>That’s all for now. More on this later, also expect this post to get revised and refined!</p>
